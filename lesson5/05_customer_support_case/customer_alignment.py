# -*- coding: utf-8 -*-
"""
æ•™ç¨‹ï¼šå®¢æœåœºæ™¯å¯¹é½æ¡ˆä¾‹åˆ†æï¼ˆæœ€å°å¯è¿è¡Œç‰ˆï¼‰
- æ„é€ å«ä¼˜é€‰/æ‹’ç»å›ç­”çš„åå¥½æ•°æ®é›†
- ä¸ºå€™é€‰å›å¤æ‰“åˆ†ï¼šcoverage & politeness
- æ€»åˆ†å…¬å¼ï¼šscore = 0.6*coverage + 0.4*politeness
- å¯¼å‡º CSV ä¾›ä¸šåŠ¡å›é¡¾
- å¯é€‰ï¼šæ¥å…¥ Qwen3 ç”Ÿæˆé¢å¤–å€™é€‰ï¼ˆé»˜è®¤å…³é—­ï¼Œç¦»çº¿å¯è·‘ï¼‰

Run:
  python cx_alignment_tutorial.py
"""

import os, csv, math, re
from dataclasses import dataclass, asdict
from typing import List, Dict, Tuple

# ===== å¯é€‰ï¼šæ˜¯å¦è°ƒç”¨é¢„è®­ç»ƒæ¨¡å‹ï¼ˆå¦‚ Qwen/Qwen3-0.6bï¼‰ç”Ÿæˆå›å¤ =====
USE_MODEL = False       # é»˜è®¤ Falseï¼šå®Œå…¨ç¦»çº¿ã€æ— éœ€ä¾èµ–
MODEL_NAME = "Qwen/Qwen3-0.6b"
MAX_NEW_TOKENS = 128

# ===== å¦‚æœå¯ç”¨æ¨¡å‹ï¼Œæ‡’åŠ è½½ transformers =====
def maybe_load_model():
    if not USE_MODEL:
        return None, None
    from transformers import AutoTokenizer, AutoModelForCausalLM
    import torch
    tok = AutoTokenizer.from_pretrained(MODEL_NAME, trust_remote_code=True, use_fast=False)
    if tok.pad_token is None and tok.eos_token is not None:
        tok.pad_token = tok.eos_token
        tok.pad_token_id = tok.eos_token_id
    model = AutoModelForCausalLM.from_pretrained(
        MODEL_NAME, trust_remote_code=True, attn_implementation="eager"
    )
    device = "cuda" if hasattr(torch, "cuda") and torch.cuda.is_available() else ("mps" if getattr(torch.backends, "mps", None) and torch.backends.mps.is_available() else "cpu")
    model.to(device).eval()
    return tok, model

def model_generate(tok, model, prompt: str) -> str:
    import torch, torch.nn.functional as F
    enc = tok(prompt, return_tensors="pt")
    enc = {k: v.to(model.device) for k, v in enc.items()}
    out = model.generate(
        **enc, max_new_tokens=MAX_NEW_TOKENS, do_sample=True, top_p=0.9, temperature=0.7,
        eos_token_id=tok.eos_token_id, pad_token_id=tok.pad_token_id
    )
    text = tok.decode(out[0], skip_special_tokens=True)
    # ä»…æˆªå–â€œå›ç­”ï¼šâ€ä¹‹åçš„éƒ¨åˆ†ï¼ˆè‹¥æœ‰ï¼‰
    m = re.search(r"å›ç­”[:ï¼š](.*)", text, flags=re.S)
    return (m.group(1).strip() if m else text.strip())[:600]

# ===== æ•°æ®å»ºæ¨¡ =====
@dataclass
class Example:
    ticket_id: str
    customer_query: str
    context_tags: List[str]          # ç”¨äºè¦†ç›–åº¦çš„ä¸»é¢˜è¯ï¼ˆäººå·¥/æ¨¡æ¿ï¼‰
    candidate_type: str              # "chosen" | "rejected" | "generated"
    reply: str
    coverage: float = 0.0            # [0,1]
    politeness: float = 0.0          # [0,1]
    score: float = 0.0               # 0.6*coverage + 0.4*politeness
    notes: str = ""                  # è¯„è¯­/åŸå› 

# ===== ç¤ºä¾‹åå¥½æ•°æ®ï¼ˆ3æ¡å·¥å•ï¼Œæ¯æ¡å« chosen/rejectedï¼‰=====
PREF_DATA: List[Tuple[str, str, List[str], str, str]] = [
    (
        "T001",
        "æˆ‘æ˜¨å¤©ä¸‹å•çš„è€³æœºä»€ä¹ˆæ—¶å€™å‘è´§ï¼Ÿå¯ä»¥å¸®æˆ‘æŸ¥ä¸‹ç‰©æµå—ï¼Ÿ",
        ["å‘è´§", "ç‰©æµ", "è®¢å•", "è€³æœº", "æŸ¥è¯¢"],
        # chosen
        "æ‚¨å¥½ï½æˆ‘å·²ä¸ºæ‚¨æŸ¥è¯¢åˆ°è¯¥è®¢å•ä»Šå¤©å·²å‡ºåº“ï¼Œé¢„è®¡24å°æ—¶å†…æ½æ”¶ã€‚"
        "è¿™é‡Œæ˜¯ç‰©æµå•å·ï¼šSF123456ï¼Œå¯åœ¨é¡ºä¸°å®˜ç½‘/å°ç¨‹åºå®æ—¶è·Ÿè¸ªã€‚"
        "è‹¥ 24 å°æ—¶å†…ä»æœªæ›´æ–°ï¼Œè¯·éšæ—¶å›å¤æˆ‘ä¸ºæ‚¨å‚¬å•ã€‚",
        # rejected
        "è‡ªå·±å»æŸ¥å¿«é€’ï¼Œæˆ‘ä»¬ä¹Ÿæ²¡åŠæ³•ã€‚"
    ),
    (
        "T002",
        "æˆ‘æƒ³ç”³è¯·é€€è´§ï¼Œè€³æœºæœ‰ç”µæµå£°ã€‚éœ€è¦æ€ä¹ˆæ“ä½œï¼Ÿ",
        ["é€€è´§", "å”®å", "æµç¨‹", "ç”µæµå£°", "è€³æœº"],
        "éå¸¸æŠ±æ­‰ç»™æ‚¨å¸¦æ¥ä¸ä¾¿ã€‚æˆ‘å¯ä»¥ååŠ©æ‚¨é€€è´§ï¼š"
        "è¯·åœ¨â€œæˆ‘çš„è®¢å•-ç”³è¯·å”®åâ€æäº¤é€€è´§ï¼ŒåŸå› é€‰æ‹©â€œæ€§èƒ½æ•…éšœâ€ã€‚"
        "ç³»ç»Ÿä¼šç”Ÿæˆä¸Šé—¨å–ä»¶å•ï¼Œå¿«é€’è´¹ç”±æˆ‘ä»¬æ‰¿æ‹…ã€‚",
        "è¿™ä¸ªé—®é¢˜ä¸æ˜¯æˆ‘ç®¡çš„ï¼Œä½ è‡ªå·±æ‰¾å”®åã€‚"
    ),
    (
        "T003",
        "æˆ‘ä¹°é”™é¢œè‰²äº†ï¼Œæƒ³æ”¹æˆé»‘è‰²ç‰ˆï¼Œè¿˜èƒ½æ”¹å—ï¼Ÿ",
        ["æ”¹è‰²", "å˜æ›´", "è®¢å•", "é»‘è‰²", "å®¢æœ"],
        "ç†è§£æ‚¨çš„éœ€æ±‚ï½è‹¥å°šæœªå‘è´§å¯ç›´æ¥ä¸ºæ‚¨æ”¹ä¸ºé»‘è‰²ã€‚"
        "æˆ‘è¿™è¾¹å…ˆæäº¤å˜æ›´ç”³è¯·ï¼ŒåŒæ—¶ç»™ä»“åº“ç•™è¨€ä¼˜å…ˆå¤„ç†ï¼›"
        "è‹¥å·²å‘è´§ä¹Ÿæ²¡å…³ç³»ï¼Œæ”¶åˆ°åæ”¯æŒæ¢è´§ã€‚",
        "ä¸è¡Œï¼Œä¸èƒ½æ”¹ã€‚"
    ),
]

# ===== ç®€æ˜“ç¤¼è²Œæ€§/è¦†ç›–åº¦è¯„åˆ†å™¨ï¼ˆè§„åˆ™æ¢é’ˆç‰ˆï¼‰=====
POLITE_POS = [
    "æ‚¨å¥½", "æŠ±æ­‰", "éå¸¸æŠ±æ­‰", "è¯·", "æ„Ÿè°¢", "è¾›è‹¦", "ä¸ºæ‚¨", "ç†è§£", "ååŠ©", "éº»çƒ¦",
    "å¾ˆæŠ±æ­‰", "å»ºè®®", "å¯ä»¥", "å°†ä¸ºæ‚¨", "å·²ä¸ºæ‚¨", "å¦‚æœ‰éœ€è¦", "æ¬¢è¿éšæ—¶"
]
POLITE_NEG = ["è‡ªå·±", "ä¸ç®¡", "ä¸è¡Œ", "æ²¡åŠæ³•", "éº»çƒ¦æ­»", "ä½ ä»¬", "é—­å˜´", "æ»š", "å·®è¯„"]

def clamp01(x: float) -> float:
    return max(0.0, min(1.0, x))

def politeness_score(text: str) -> float:
    t = text.strip()
    pos = sum(t.count(w) for w in POLITE_POS)
    neg = sum(t.count(w) for w in POLITE_NEG)
    raw = 0.5 + 0.15*pos - 0.25*neg
    return clamp01(raw)

def coverage_score(query: str, tags: List[str], reply: str) -> float:
    """
    ç²—ç•¥è¦†ç›–åº¦ï¼šå›å¤ä¸­å‘½ä¸­å¤šå°‘ä¸Šä¸‹æ–‡æ ‡ç­¾ï¼ˆå»é‡ï¼‰ï¼Œå¹¶å¥–åŠ±æä¾›â€œå¯æ‰§è¡ŒåŠ¨ä½œâ€çš„æç¤ºè¯ã€‚
    """
    r = reply.lower()
    hits = 0
    for k in set(tags):
        if k.lower() in r:
            hits += 1
    base = hits / max(1, len(set(tags)))
    # ç®€æ˜“â€œå¯æ‰§è¡ŒåŠ¨ä½œâ€è¯å¥–åŠ±
    action_bonus = 0.1 if any(w in r for w in ["æŸ¥è¯¢", "å•å·", "ç”³è¯·", "æäº¤", "æ›´æ”¹", "ä¸Šé—¨", "é€€è´§", "æ¢è´§"]) else 0.0
    return clamp01(base + action_bonus)

def total_score(coverage: float, politeness: float) -> float:
    return clamp01(0.6*coverage + 0.4*politeness)

def annotate(example: Example) -> Example:
    example.coverage   = coverage_score(example.customer_query, example.context_tags, example.reply)
    example.politeness = politeness_score(example.reply)
    example.score      = total_score(example.coverage, example.politeness)
    # ç”Ÿæˆç®€å•è¯„è¯­
    notes = []
    if example.coverage < 0.5: notes.append("è¦†ç›–ä¸è¶³")
    if example.politeness < 0.5: notes.append("ç¤¼è²Œæ€§å¼±")
    if example.coverage >= 0.7: notes.append("è¦†ç›–å……åˆ†")
    if example.politeness >= 0.7: notes.append("ç¤¼è²Œåˆ°ä½")
    example.notes = "ï¼›".join(notes) if notes else "è¡¨ç°è‰¯å¥½"
    return example

def build_dataset() -> List[Example]:
    rows: List[Example] = []
    for (tid, query, tags, pos, neg) in PREF_DATA:
        rows.append(annotate(Example(tid, query, tags, "chosen",   pos)))
        rows.append(annotate(Example(tid, query, tags, "rejected", neg)))
    # å¯é€‰ï¼šæ¨¡å‹ç”Ÿæˆé¢å¤–å€™é€‰
    if USE_MODEL:
        tok, model = maybe_load_model()
        if tok is not None:
            for (tid, query, tags, _, _) in PREF_DATA:
                prompt = f"é—®é¢˜ï¼š{query}\nè¯·ç”¨ç¤¼è²Œã€åŒç†å¿ƒã€ä¸”å¯æ‰§è¡Œçš„æ­¥éª¤è¿›è¡Œå›å¤ã€‚å›ç­”ï¼š"
                gen = model_generate(tok, model, prompt)
                rows.append(annotate(Example(tid, query, tags, "generated", gen)))
    return rows

def export_csv(rows: List[Example], out_path="outputs/cx_alignment_review.csv"):
    os.makedirs(os.path.dirname(out_path), exist_ok=True)
    headers = ["ticket_id","candidate_type","score","coverage","politeness","customer_query","reply","context_tags","notes"]
    with open(out_path, "w", newline="", encoding="utf-8") as f:
        w = csv.writer(f)
        w.writerow(headers)
        for r in rows:
            w.writerow([
                r.ticket_id, r.candidate_type, f"{r.score:.3f}",
                f"{r.coverage:.3f}", f"{r.politeness:.3f}",
                r.customer_query, r.reply, "|".join(r.context_tags), r.notes
            ])
    return out_path

def print_brief_report(rows: List[Example], top_k=3):
    print("\n=== æ€»è§ˆ ===")
    avg = sum(r.score for r in rows)/len(rows)
    print(f"æ ·æœ¬æ•°ï¼š{len(rows)}ï¼›å¹³å‡æ€»åˆ†ï¼š{avg:.3f}")
    print("\n=== Top è¡¨ç° ===")
    for r in sorted(rows, key=lambda x: x.score, reverse=True)[:top_k]:
        print(f"[{r.candidate_type}] {r.ticket_id}  score={r.score:.3f}  cov={r.coverage:.3f}  pol={r.politeness:.3f}")
        print("  â–¶", r.reply[:120].replace("\n"," "), "...")
    print("\n=== éœ€æ”¹è¿› ===")
    for r in sorted(rows, key=lambda x: x.score)[:top_k]:
        print(f"[{r.candidate_type}] {r.ticket_id}  score={r.score:.3f}  cov={r.coverage:.3f}  pol={r.politeness:.3f}")
        print("  â–¶", r.reply[:120].replace("\n"," "), "...")

def main():
    rows = build_dataset()
    out_csv = export_csv(rows)
    print_brief_report(rows)
    print(f"\nâœ… ç»“æœå·²å¯¼å‡ºï¼š{out_csv}")
    print("ğŸ‘‰ å¯ç”¨ Excel/Numbers æ‰“å¼€ï¼›æˆ–å¯¼å…¥åˆ°æ•°æ®çœ‹æ¿ä¾›ä¸šåŠ¡å›é¡¾ã€‚")

if __name__ == "__main__":
    main()
