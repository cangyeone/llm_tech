# 教程：QLoRA 的三大关键技术解析

## 学习目标
- 理解 NF4 量化如何将浮点权重映射到 4 bit 表达以节省显存。
- 掌握分页优化器（paged optimizers）在梯度存储上的节省原理。
- 了解梯度检查点（gradient checkpointing）对激活显存的影响估算方法。

## 背景原理
1. **NF4 量化**：通过非对称映射将张量值投影到离散集合 $\{q_{\min}, ..., q_{\max}\}$，近似为 $x \approx \text{round}(x/\alpha) \cdot \alpha$。
2. **分页优化器**：以分页方式将优化器状态驻留在 CPU 内存，仅在需要时调入 GPU，有效减少显存占用。
3. **梯度检查点**：在反向传播时重新计算前向激活，将激活存储从 $\mathcal{O}(L)$ 降低到 $\mathcal{O}(\sqrt{L})$，实现空间换时间。

## 代码结构解析
- `QLoRAStats`：用超参数（隐藏维度、层数等）估算参数规模。
- `nf4_quantize`：对随机张量执行 NF4 量化，打印缩放因子与离散范围。
- `estimate_paged_memory`：比较 FP16 与 INT4 状态下的显存占用，展示分页优化器优势。
- `gradient_checkpointing_saving`：根据序列长度与层数计算激活节省的体积。

## 实验步骤
1. 运行脚本观察日志中的 scale、显存对比与激活节省值。
2. 修改 `hidden_size`、`num_layers` 模拟不同模型规模，分析节省比例。
3. 对比无分页优化器时的显存消耗（可将 `optimizer_state` 修改为 FP16 计算）。

## 延伸讨论
- 在实际训练中，NF4 量化的误差如何通过 LoRA 适配器抵消？
- 分页优化器会带来 CPU-GPU 数据搬运开销，可通过重叠通信与计算来缓解。
- 梯度检查点会增加反向传播的计算时间，如何权衡显存节省与训练速度？
