
# 课程实验 6：对齐数据集构建与质量分析

本脚本提供了对齐数据集的清洗、打分与可视化流程，帮助学生理解高质量偏好数据的重要性。通过对数据集进行过滤、相似度计算、质量打分等操作，最终得出清洗后的数据集供后续使用。

---

## 目录
- [课程实验 6：对齐数据集构建与质量分析](#课程实验-6对齐数据集构建与质量分析)
  - [目录](#目录)
  - [功能概览](#功能概览)
  - [环境与依赖](#环境与依赖)
    - [所需库：](#所需库)
    - [安装依赖：](#安装依赖)
  - [快速开始](#快速开始)
    - [步骤 1：安装所需的库](#步骤-1安装所需的库)
    - [步骤 2：运行脚本](#步骤-2运行脚本)
    - [步骤 3：查看分析结果](#步骤-3查看分析结果)
  - [命令行参数](#命令行参数)
  - [代码结构与功能说明](#代码结构与功能说明)
    - [数据加载与处理](#数据加载与处理)
    - [数据清洗与过滤](#数据清洗与过滤)
    - [相似度计算与质量评估](#相似度计算与质量评估)
    - [数据可视化](#数据可视化)
    - [数据清洗与结果输出](#数据清洗与结果输出)
  - [输出与结果分析](#输出与结果分析)
    - [示例输出：](#示例输出)
  - [常见问题（FAQ）](#常见问题faq)
  - [扩展建议](#扩展建议)
  - [许可证](#许可证)

---

## 功能概览

本脚本的核心功能包括：

- **数据加载与处理**：加载并重命名数据集字段，选择数据集的一部分进行清洗和分析。
- **数据过滤**：按文本长度过滤掉过短或过长的样本。
- **相似度计算与质量评估**：使用 **TF-IDF** 向量化并计算 **cosine similarity**，过滤掉重复或低多样性的样本。
- **数据可视化**：展示数据集中 **prompt** 长度的分布，帮助分析数据的多样性。

---

## 环境与依赖

### 所需库：
- Python ≥ 3.7
- `torch`
- `datasets`
- `sklearn`
- `matplotlib`
- `pandas`
- `numpy`

### 安装依赖：
```bash
pip install torch datasets scikit-learn matplotlib pandas numpy
```

---

## 快速开始

### 步骤 1：安装所需的库
```bash
pip install torch datasets scikit-learn matplotlib pandas numpy
```

### 步骤 2：运行脚本
```bash
python lesson4/06_dataset_curation/dataset_curation.py
```

### 步骤 3：查看分析结果
脚本会自动加载数据集，进行清洗、过滤，并输出包含质量标记的清洗数据集。最终的清洗结果会被保存为 CSV 文件，默认保存在 `./outputs/curated_pairs.csv`。

---

## 命令行参数

脚本支持以下命令行参数：

| 参数                  | 默认值                         | 说明 |
|-----------------------|--------------------------------|------|
| `--dataset`            | `Dahoas/rm-static`             | 数据集名称或路径 |
| `--split`              | `train[:1%]`                   | 数据集的子集，例如训练集的 1% |
| `--output`             | `./outputs/curated_pairs.csv`  | 清洗后数据集的输出路径 |
| `--min-length`         | `32`                           | 最小文本长度 |
| `--max-length`         | `2048`                         | 最大文本长度 |
| `--sim-threshold`      | `0.2`                          | 相似度阈值，用于判断是否为重复数据 |

---

## 代码结构与功能说明

### 数据加载与处理

- **`load_pairs(args: CurationArgs)`**  
  加载数据集并选择指定的字段（`prompt`、`chosen` 和 `rejected`）。如果数据集路径已存在，则从本地加载，否则从 Hugging Face 加载指定的数据集。

### 数据清洗与过滤

- **`filter_by_length(dataset: Dataset, args: CurationArgs)`**  
  该函数根据 **min_length** 和 **max_length** 参数过滤掉长度不符合要求的文本。每条数据（包括 `prompt`、`chosen` 和 `rejected`）的长度都将被检查。

### 相似度计算与质量评估

- **`compute_similarity_flags(dataset: Dataset, threshold: float)`**  
  使用 **TF-IDF** 向量化和 **cosine similarity** 计算每条数据的 **prompt**、**chosen** 和 **rejected** 之间的相似度。若相似度大于阈值，则认为是重复或低多样性数据。

### 数据可视化

- **`visualize_distribution(dataset: Dataset)`**  
  使用 **matplotlib** 展示数据集中 **prompt** 的长度分布，帮助分析数据的多样性。

### 数据清洗与结果输出

- **`curate(args: CurationArgs)`**  
  该函数执行数据集的加载、清洗、过滤、相似度计算和可视化，并最终输出清洗后的数据集（CSV 格式）。函数还会输出疑似重复或低多样性数据的统计信息。

---

## 输出与结果分析

清洗后的数据集将被保存为 CSV 文件，并提供以下信息：

- **`is_redundant`**：表示是否为疑似重复或低多样性数据（通过相似度阈值判断）。
- **`prompt`**、**`chosen`** 和 **`rejected`**：每个数据条目的问题和两个候选答案。

### 示例输出：
```csv
ticket_id,prompt,chosen,rejected,is_redundant
1,我能取消订单吗？,是的，您可以通过应用程序取消订单,取消订单需要通过客服联系,False
2,如何更改付款方式？,请在结账时选择新的付款方式,您需要联系客户服务,True
...
```

---

## 常见问题（FAQ）

1. **问题：如何处理加载的数据集格式问题？**
   - **解决方案**：确保数据集包含 `prompt`、`chosen` 和 `rejected` 字段。如果加载的数据集没有这些字段，请检查数据集的结构并进行相应的修改。

2. **问题：如何调整相似度阈值？**
   - **解决方案**：可以通过命令行参数 `--sim-threshold` 设置不同的相似度阈值，默认值为 `0.2`。

3. **问题：如何调整数据集的长度过滤条件？**
   - **解决方案**：可以通过命令行参数 `--min-length` 和 `--max-length` 设置文本的最小和最大长度，默认值分别为 `32` 和 `2048`。

---

## 扩展建议

- **多样性分析**：可以扩展脚本来分析数据集的多样性，比如使用 **distinct-n** 或 **self-BLEU** 等指标。
- **多语言支持**：为支持不同语言的数据集，可以修改相似度计算函数，使用适合不同语言的向量化方法。
- **可视化增强**：除了文本长度分布，可以加入更多的可视化，比如数据集的标签分布等。

---

## 许可证

此脚本仅用于教学和研究目的。请遵守所用数据集和模型的许可协议。
