# 教程：结合微调模型与检索的混合推理

## 学习目标
- 理解检索增强生成（RAG）与纯模型回答的动态切换策略。
- 学会根据检索得分判断是否需要融合上下文。
- 构造混合推理引擎，输出响应文本与诊断指标。

## 背景原理
在生产环境中，检索结果质量可能波动。可根据检索得分决定：

$$
\text{mode} = \begin{cases}
\text{RAG融合}, & \bar{s} \geq \tau \\
\text{模型fallback}, & \bar{s} < \tau
\end{cases}
$$

其中 $\bar{s}$ 为检索得分平均值，$\tau$ 为融合阈值。若完全无检索结果，则直接使用微调模型回答。

## 代码结构解析
- `FineTunedModel`：模拟加载好的微调模型，提供 `generate` 接口。
- `HybridInferenceEngine`：
  - `build_prompt` 拼接检索上下文。
  - `fuse` 根据平均得分决定使用 RAG 融合或 fallback。
- `mock_retrieval`：根据关键词返回模拟检索结果，课堂可替换为实际引擎。
- `main`：解析命令行参数，执行融合流程并打印指标。

## 实践步骤
1. 运行示例：
   ```bash
   python hybrid_inference.py "客户咨询发票寄送时间" --threshold 0.5
   ```
2. 观察输出的回答与 `metrics`，判断是否采用了检索融合。
3. 调高阈值，模拟检索得分较低的场景，验证 fallback 行为。
4. 替换 `mock_retrieval` 为真实检索接口，结合 Qwen 微调模型部署混合推理服务。

## 拓展问题
- 如何使用更复杂的指标（如 top-k 平均得分、置信区间）决定融合策略？
- 在低延迟场景下，是否需要缓存检索结果或模型回答？
- 结合在线反馈数据（满意度、点击率）动态调整阈值是否可行？
