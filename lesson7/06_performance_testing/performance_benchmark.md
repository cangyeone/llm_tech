# 教程：检索延迟与生成速度的性能压测

## 学习目标
- 模拟 RAG 系统在不同阶段的延迟分布，收集统计指标。
- 计算平均值、P95、最大值等关键指标，评估性能瓶颈。
- 根据指标结果制定优化策略，如缓存、量化、并行化等。

## 背景原理
性能压测旨在评估系统稳定性与容量。常用指标包括：
- **平均延迟**：衡量整体响应速度。
- **P95**：95% 请求的延迟阈值，评估尾部延迟。
- **最大值**：监控极端情况，识别潜在风险。

## 代码结构解析
- `BenchmarkConfig` / `BenchmarkResult`：定义压测配置与结果。
- `simulate_latency`：在指定范围内随机生成延迟，模拟真实系统表现。
- `_statistics`：计算 avg、P95、max。
- `diagnose`：根据检索与生成平均延迟比较，给出优化建议。
- `main`：解析命令行参数，运行压测并输出结果。

## 实践步骤
1. 执行压测：
   ```bash
   python performance_benchmark.py --queries 30 --retrieval 50 120 --generation 200 500
   ```
2. 查看 JSON 结果与诊断提示，判断检索或生成阶段是否成为瓶颈。
3. 调整延迟范围模拟不同硬件/负载情况，讨论优化手段。
4. 将真实监控数据替换 `simulate_latency` 的随机逻辑，实现线上回放。

## 拓展问题
- 如何引入并发（多线程/多进程）模拟真实 QPS？
- 可否结合 Prometheus/Grafana 将压测结果可视化？
- 当系统尾部延迟过高时，是否需要限流或降级策略？
